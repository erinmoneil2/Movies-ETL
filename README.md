# Movies-ETL

## Overview 
The purpose of this challenge was to use the Extract, Transform, Load method to refactor and process large sets of data. We used the ETL process in order to take large sets of data from open source websites and make them into more intuitive datasets. This particular data set was made to help the company Amazing Prime for a hackathon, and then use this table to update daily as new information is loaded. 

The Extract stage is the initial retrieval and reading of data from Wikipedia and Kaggle into CSV and JSON readable files by using a python environment. 

The Transform stage is the iterative data cleaning process. 

The Load stage happens after the data is cleaned and loaded into the appropriate tables/schemas to help interpret and read the data. 
